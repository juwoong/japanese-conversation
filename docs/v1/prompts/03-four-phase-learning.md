# 4 Phase 학습 엔진: 관찰 · 포착 · 참여 · 정리

## 목표

현재 단일 구조 `SessionScreen`(대사 표시 → 녹음 → 피드백)을 4단계 순환 학습 엔진으로 전면 교체합니다.
듣기만 하다가 갑자기 말하게 하지 않는 설계 — 관찰(Watch) → 포착(Catch) → 참여(Engage) → 정리(Review).
첫 방문에서도 산출(말하기) 비율 40% 이상을 달성합니다.

이 플랜에는 다음 기능이 포함되어 있습니다.

1. Phase 1 관찰: 모델 대화 시청 (소리+히라가나, 한국어 안전망)
2. Phase 2 포착: 청크 캐치 → 단어 캐치 → 소리 구별 → 따라 말하기 → 그림→말하기
3. Phase 3 참여: AI NPC와 실전 대화 (선택지 → 빈칸 → 자유 입력 단계적 전환)
4. Phase 4 정리: 핵심 표현 정리 + "왜 이렇게 말할까?" + 발음 피드백

## 요구 결과물

1. `SessionScreen.tsx` 전면 리디자인 — 4 Phase state machine
2. Phase별 컴포넌트: `WatchPhase.tsx`, `CatchPhase.tsx`, `EngagePhase.tsx`, `ReviewPhase.tsx`
3. 포착용 활동 컴포넌트: `ChunkCatch.tsx`, `WordCatch.tsx`, `SoundDistinction.tsx`, `ShadowSpeak.tsx`, `PictureSpeak.tsx`
4. 참여용 활동 컴포넌트: `ChoiceInput.tsx`, `FillBlank.tsx`, `FreeInput.tsx`
5. 시뮬레이터에서 1개 상황(식당)의 4 Phase 전체 플로우 완주 확인
6. Phase 사이에 로딩 화면이나 단계 안내 없이 연속된 경험이 되는지 확인

## 타겟 프로젝트

`app/` 밑에 있는 메인 서비스를 대상으로 합니다.

## 전체 프로세스 주의사항

1. 하나의 스텝이 완료되면 git commit이 발생되어야 합니다.
2. 하나의 스텝이 완료되면 자동으로 다음 스텝으로 넘어가세요.
3. 모든 프로젝트 작성과, 실행을 통한 검증이 완료되기 전까지는 스텝과 루프를 종료하지 마세요.
4. 더 이상 진행할 수 없을 정도로 모호한 경우에만 중단하고 질문을 요청하세요.
5. 적절한 agent team 멤버를 구성하세요. 모든 작업에는 무조건 리뷰어가 할당되어야 하며, 각 스텝의 완료 직전에도 리뷰가 진행되어야 합니다.
6. 절대 전체 프로세스를 컨텍스트에서 관리하지 마세요. PLAN.md 파일을 이용하십시오.
7. 이 프롬프트는 가장 복잡한 변경입니다. 반드시 Phase별로 분리하여 구현+테스트하세요. 한 번에 4 Phase를 모두 만들려고 하지 마세요.

## 상세 프로세스

### 1. 세션 state machine 설계 및 데이터 모델 정의

현재 `SessionScreen.tsx`와 `useSession` 훅을 읽고, 기존 상태 관리 방식을 파악합니다.
그리고 4 Phase를 관통하는 state machine을 설계합니다.

**state machine 설계:**

```typescript
type SessionPhase = 'watch' | 'catch' | 'engage' | 'review';

interface SessionState {
  phase: SessionPhase;
  situationSlug: string;
  modelDialogue: ModelLine[];      // Phase 1에서 사용
  keyExpressions: Expression[];     // Phase 2~4에서 사용
  catchActivities: CatchActivity[]; // Phase 2 세부 활동
  engageTurns: EngageTurn[];       // Phase 3 대화 턴
  userPerformance: Performance;     // Phase 4 요약용
  visitCount: number;               // 재방문 시 포착 구성 변경
  inputMode: 'voice' | 'silent';   // 01-onboarding에서 전달
}
```

**Phase 간 전환 규칙:**
- Phase 사이에 로딩/안내 화면 없음
- 전환은 fade 또는 슬라이드 애니메이션으로 자연스럽게
- 각 Phase가 완료 조건을 충족하면 자동으로 다음 Phase 진입

해당 작업에는 다음 에이전틱 팀이 구성되어야 합니다.

1. 소프트웨어 아키텍트 — state machine 설계 리뷰
2. 프론트엔드 엔지니어 — React Native에서의 구현 가능성 검증

### 2. Phase 1 — 관찰(Watch) 구현

모델 대화를 보고 듣는 Phase입니다. 30초~1분.

**구현 세부사항:**
- 대화가 한 줄씩 자동 순차 재생 (TTS)
- 자막은 히라가나만 (한자 ✕, 한국어 발음 ✕)
- 핵심 표현은 살짝 다른 색상으로 하이라이트
- 말풍선 탭 → 해당 줄만 다시 재생
- [💬 한국어로 보기] 탭하면 각 줄 옆에 한국어 뜻이 회색으로 3초 표시 후 소멸
- 모델 대화: 4~6턴, 핵심 표현 3~5개
- 기존 `NpcBubble`, `UserBubble` 컴포넌트 재활용/확장

**데이터 소스:**
- 기존 `scripts/output/*.json`의 lines 데이터 활용
- NPC/User 구분은 `speaker` 필드로 판단

해당 작업에는 다음 에이전틱 팀이 구성되어야 합니다.

1. 프론트엔드 엔지니어
2. QA 엔지니어 — TTS 재생 타이밍, 한국어 안전망 소멸 타이밍 검증

### 3. Phase 2 — 포착(Catch) 구현

핵심 소리를 건져올리는 Phase입니다. 1.5~2.5분.

**5가지 활동을 순서대로 구현합니다:**

#### a. 청크 캐치 (수용, ~20초)
전체 발화 듣고 상황 그림 고르기. 3개 선택지 (이모지+텍스트).
문장 전체를 하나의 소리 덩어리로 인식하는 훈련.

#### b. 단어 캐치 (수용, ~30초)
핵심 단어만 듣고 그림 고르기. 수량→숫자 시각화, 구체 명사→사물 그림, 행위→상황 그림.
정답 시 소리 + [?] 표시. 한국어 없이 소리→그림 직접 연결.

#### c. 소리 구별 (수용, ~15초, 간헐적)
최소 대립쌍 듣기. "같은 말일까요? [같다] [다르다]"
해당 상황에 음소 구별이 중요한 쌍이 있을 때만 삽입.

#### d. 따라 말하기 (산출, ~20초)
소리 듣고 따라 발화. 묵음 모드: "머릿속으로 해보기" 탭 → 정답 음성 재생.

#### e. 그림→말하기 (산출, ~25초)
점원 질문 음성 + 상황 그림 → 사용자 발화. 참여의 예고편.

**재방문 시 변화:**
| 방문 | 포착 구성 |
|------|----------|
| 1회 | 풀 세트 |
| 2회 | 단어 캐치 생략, 산출부터 |
| 3회+ | 변주 시나리오의 새 단어만 |
| 숙련 | "바로 대화로" 스킵 가능 |

해당 작업에는 다음 에이전틱 팀이 구성되어야 합니다.

1. 프론트엔드 엔지니어 2명 — 수용 활동 + 산출 활동 분담
2. QA 엔지니어 — 5개 활동 순서대로 실행, 재방문 시 구성 변경 확인

### 4. Phase 3 — 참여(Engage) 구현

AI NPC와 실전 대화 Phase입니다. 5~8분. 산출 비율 40% 이상.

**입력 난이도 3단계:**

```
[첫 시도] 선택지 + 따라말하기  →  [2~3회차] 빈칸 채우기  →  [숙련] 자유 입력
```

**선택지 규칙 (반드시 반영):**
- 히라가나 + 음성으로만 구성 (한국어 없음)
- 오답도 문법적으로 맞는 일본어 (문법 오류를 선택지에 넣지 않음)
- 오답이 오답인 이유는 "상황이 다를 뿐" — 변주 시나리오에서 정답이 됨
- 🔊 탭으로 선택 전에 발음 미리 듣기 가능

**난이도 전환 기준:**
| | 선택지 → 빈칸 | 빈칸 → 자유 |
|--|---------------|-------------|
| 정답률 | 80%+ (2회 연속) | 80%+ (2회 연속) |
| 방문 횟수 | 3회+ | 5회+ |

한 세션 안에서 섞어서 전환. "갑자기 어려워졌다"를 방지.

**선택 후 따라 말하기:**
선택지를 고른 후 "이제 직접 말해보세요" → 🔊 모델 음성 → [🎤 녹음 시작]

해당 작업에는 다음 에이전틱 팀이 구성되어야 합니다.

1. 프론트엔드 엔지니어
2. SLA(제2언어습득) 관점 리뷰어 — 산출 비율, 난이도 전환 기준의 적절성 검증

### 5. Phase 4 — 정리(Review) 구현

핵심 표현 정리 + 문화적 설명 Phase입니다. 2~3분.

**화면 구성:**
- 이번 세션의 핵심 표현 목록 (🔊 재생 + [?] 뜻 확인)
- [왜 이렇게 말할까? ▾] 접힘 패널 — 호기심 프레이밍
- 발음 피드백 (음성 입력 시에만 표시)
- [지도로 돌아가기] 버튼

**[왜 이렇게 말할까?] 규칙:**
- 문법 용어 없음
- 예문 3개 이상 (패턴 추출 최소 수)
- 전부 같은 상황 안의 예문 (맥락 이탈 없음)
- 마지막 줄에서 생산성 암시 ("뭘 넣어도 같은 패턴이에요")
- 뜻은 괄호 안 간략 제공

**점수/평가 없음:**
- ⛔ "85점", "정답률 70%"
- ✅ "이 상황을 혼자 해결할 수 있어요"

해당 작업에는 다음 에이전틱 팀이 구성되어야 합니다.

1. 프론트엔드 엔지니어
2. 카피라이터 — "왜 이렇게 말할까?" 설명 텍스트의 자연스러움 검증

### 6. 식당 상황으로 전체 플로우 통합 테스트

식당(restaurant) 상황 하나를 기준으로 4 Phase 전체를 실행합니다.

**식당 모델 대화 (v1 기획서 기준):**
```
👤 いらっしゃいませ! なんめいさまですか?
🧑 ふたりです。
👤 こちらへどうぞ。
```

**검증 체크리스트:**
- [ ] 관찰: 대화 자동 재생, 한국어 안전망 3초 소멸
- [ ] 포착: 5개 활동 순차 실행, 재방문 시 구성 변경
- [ ] 참여: 선택지 → 따라 말하기, 산출 비율 확인
- [ ] 정리: 핵심 표현 목록, "왜 이렇게 말할까?" 패널
- [ ] Phase 간 전환: 로딩 없이 자연스러운 전환
- [ ] 묵음 모드: 녹음 버튼 대신 탭 기반 대체

해당 작업에는 다음 에이전틱 팀이 구성되어야 합니다.

1. QA 엔지니어 3명 — 각각 다른 경로(첫 방문/재방문/묵음모드)로 테스트
2. 프론트엔드 엔지니어 — 버그 수정

## 참고사항

1. 이 프롬프트는 전체 리디자인 중 가장 큰 변경입니다. Phase별로 분리하여 순차 구현+테스트하세요.
2. 기존 `SessionScreen`의 녹음/STT/피드백 로직은 Phase 3(참여)에서 재활용합니다.
3. 기존 `useSession` 훅은 4 Phase에 맞게 리팩토링하거나 새로 작성합니다.
4. 포착의 그림 선택지는 MVP에서 이모지로 대체합니다.
5. AI NPC 대화 (Phase 3)의 상세 규칙은 `04-ai-npc-feedback.md`에 별도로 정의됩니다.
6. 관련 v1 기획서: `docs/v1/Part2_4Phase.md` 전체
